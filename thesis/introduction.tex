\chapter{Introduction}

% Target length: 1,5 pages.

Generative modelling is a highly active branch of machine learning aiming to
capture the distribution of a certain feature set, be it images
\citep{saharia2022hierarchical,ramesh2022hierarchical}, text
\citep{brown2020language}, or graphs \citep{guo2020systematic}. Modelling this
distribution presents a lot of advantages, but it is particularly consequential
in biology \citep{lopez2020enhancing,strokach2022deep}. In protein science, the
application of generative models can solve the frequently occurring problem of
generating novel proteins to perform a specific industrial, experimental, or
therapeutic function \citep{jendrusch2021alphadesign, madani2020progen,
  madani2021deep}. This process has so far been restricted to experimental
techniques such as directed evolution, which is costly both in time and
resources \citep{wang2021directed}.

Generating novel samples has generally been most successful by using
differentiable architectures such as autoregressive models, the most successful
being transformers \citep{vaswani2017attention}, and \acrfull{gans}
\citep{goodfellow2014generative}. While most of the efforts in this field have
been focusing on generating novel amino acid sequences analogous to natural
sequences fulfilling desired properties
\citep{riesselman2018deep,biswas2021low,weinstein2021structured,repecka2021expanding,kucera2022conditional},
there have been several attempts at taking structural aspects of proteins into
account, since structural features ultimately determine a protein's function
\citep{anand2018generative, ingraham2019generative, maddhuri2021protein}.

However, the design and improvement of generative models applied to proteins is
prohibited by the lack of suitable evaluation metrics. It is notoriously hard to
find expressive, robust and efficient performance measures that accurately gauge
the quality of generated samples \emph{in-silico} \citep{theis2016note,
betzalel2022study}. Efforts have been made to solve this challenge in the image
domain by using the fixed-length representations obtained from a neural network
such as the Inception v3 network, and subsequently calculating a Wasserstein
distance between the set of generated samples and test data using such
representations \citep{heusel2017gans}. Recently, the community has investigated
this challenge specifically for a common representation of proteins: graphs
\citep{thompson2022evaluation, obray2022evaluation}. In this domain, the
standard measure used is a highly versatile statistic for a kernel two-sample
test called \acrfull{mmd} introduced by \cite{gretton2012kernel}. \acrshort{mmd}
computes the distance between two sets of data by computing a distance measure
in a \acrfull{rkhs}, so its versatily stems from the fact that any valid kernel
and appropriate underlying data representation can be used. However, this
framework has yet to be applied to proteins, with practitioners mostly relying
on either sequence model evaluation metrics such as perplexity scores
\citep{belinkov2019analysis,ingraham2019generative,hesslow2022rita},
physics-based tools to validate 3D structures such as RosettaRemodel
\citep{huang2011rosettaremodel, anand2018generative,ingraham2019generative},
which has sometimes limited applicability \citep{leman2020macromolecular}, or
experimental validation \citep{strokach2020fast}. While experimental validation
is the ultimate metric, better metrics for the fast \emph{in-silico} assessment
of generative proteins is required, and the flexibility of MMD could be
leveraged to fill this gap.

\cite{obray2022evaluation} recently performed an in-depth evaluation of
\acrshort{mmd}, and their results unveiled a number of pitfalls related to
\acrshort{mmd}. Depending on the kernel and its associated parameters,
different \acrshort{mmd} configurations ranked the quality of samples generated
by different models differently. In addition, when progressively perturbing a
set of synthetic graphs, certain \acrshort{mmd} configurations with respect to
another set of unperturbed graphs issued from the same distribution was not
always found to monotonically increase with increasing amounts of perturbations,
casting doubt on the expressivity of \acrshort{mmd} in certain configurations
and data.

In this thesis, we set out to clarify the behaviour of different \acrshort{mmd}
configurations on protein data sets and perform a meta-evaluation of
\acrshort{mmd}-based metrics. We investigate the behaviour of various
\acrshort{mmd} configurations by applying perturbations to one set of proteins.
These perturbations were actively designed to be relevant for protein design use
cases and include sequence perturbations, graph perturbations and geometric
perturbations. In this setting, we investigate the behaviour of frequently used
\acrshort{mmd} configurations typically used to evaluate generative models in
the graph domain. In addition, we expand this set of configurations by devising
novel combinations of protein representations, descriptors, and kernels, all
relevant for different aspects of protein design, and integrate them to the
well-established \acrshort{mmd} evaluation framework.

This thesis is organized as follows: first, Chapter \ref{chap:background}
introduces fundamental concepts that we are going to build upon, and discusses
the surrounding literature. Chapter \ref{chap:methods} details the methodology
of the experiments that we carry out in this thesis, as well as
describes all the configurations of \acrshort{mmd} that we will explore (i.e. all
combinations of representations, descriptor functions, kernels, and kernel
parameters). Chapter \ref{chap:results} presents and contextualizes the findings of those
experiments. We summarize key findings, make recommendations for practitioners and
highlight some limitations and directions for future work in Chapter
\ref{chap:discussion} before concluding in Chapter \ref{chap:conclusion}.

% Graph representations encapsulates a wide variety of data. Show how they can
% be useful in biology.

% Leslie paper: even worse, depending on parametrization, different models come
% out on top. Call for principled metric design is open.

% Machine learning for graphs. Describe different tasks. Discriminative vs.
% generative modelling.

% Challenges with generative modelling assessment, especially with related to
% graphs vs images. Situate within proteins. Show that it builds on Obray et al.

% Thesis overview
