\chapter{Methods}

% Dummy text.% Don't forget about precomputign difference between x and y in
% % Gaussian kernels

The primary methodology employed in this thesis to assess the quality of metrics
used to evaluate generative protein models follows a fundamentally similar
approach used by \cite{o2021evaluation}, which we adapt to include the following
steps:

\begin{enumerate}
\item Take two i.i.d. samples a database of proteins.
\item Apply some perturbation to one of the samples.
\item Measure the MMD between the unperturbed and perturbed sample.
\end{enumerate}

We start by motivating the datasets that will be used to simulate a
generative protein model. We then enumerate and justify the configurations of maximum mean
discrepancy that will be tested, including all the combinations of protein
representations, descriptor functions, and kernels. Finally, we describe and
motivate the experimental setups -- i.e. perturbations -- that we will employ to
test the various metric configurations.


\section{Datasets}

Because generative models have not been applied to proteins yet, which is partly due to
the lack of suitable evaluation metrics, no generative model can be used here.
In this thesis, we will use the EBI AlphaFold2Recently, however, the emergence of AlphaFold2

\section{Perturbations}

\section{MMD Configurations}

\section{Experimental Setup}

\section{Summary}
